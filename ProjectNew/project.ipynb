{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b02451-c710-4547-8cac-8f795470bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade grpcio grpcio-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8799ec51-d0be-4c4f-a4ad-4e8ad539f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "605a33c7-17ed-42c1-9e6e-be50b0addb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-27 08:09:08.225726: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-27 08:09:08.241334: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737965348.257538    2050 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737965348.262438    2050 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-27 08:09:08.279099: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gymnasium.spaces.utils import flatten\n",
    "from gymnasium.envs.registration import register, registry\n",
    "import time\n",
    "import numpy as np\n",
    "import pygame\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Any, Dict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorboard\n",
    "\n",
    "from stable_baselines3 import PPO, A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import VecNormalize, DummyVecEnv\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6482d68a-fce7-40e6-8d5a-275862ba21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'MarineEnv-v0' not in registry:\n",
    "    register(\n",
    "        id='MarineEnv-v0',\n",
    "        entry_point='environments:MarineEnv',  # String reference to the class\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c1337d-61df-4e2c-ae20-98ec70f98b2e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3cfe3-f53f-4a9e-b7f9-f5954238fcf6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "N_TRIALS = 100  # Maximum number of trials\n",
    "N_JOBS = 1 # Number of jobs to run in parallel\n",
    "N_STARTUP_TRIALS = 5  # Stop random sampling after N_STARTUP_TRIALS\n",
    "N_EVALUATIONS = 2  # Number of evaluations during the training\n",
    "N_TIMESTEPS = int(2e4)  # Training budget\n",
    "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS)\n",
    "N_EVAL_ENVS = 10\n",
    "N_EVAL_EPISODES = 10\n",
    "TIMEOUT = int(60 * 15)  # 15 minutes\n",
    "\n",
    "ENV_ID = 'MarineEnv-v0'\n",
    "\n",
    "DEFAULT_HYPERPARAMS = {\n",
    "    \"policy\": \"MlpPolicy\",\n",
    "    \"env\": ENV_ID,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3bf52b-6b8c-4b0b-9e54-2fddb2790918",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def sample_ppo_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
    "    \n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1, log=True)  # Learning rate (log scale)\n",
    "    \n",
    "    n_steps = 2 ** trial.suggest_int('n_steps', 7, 12)  # Number of steps per update (512-4096)\n",
    "    \n",
    "    batch_size = 2 ** trial.suggest_int('batch_size', 5, 10)  # Minibatch size (32-1024)\n",
    "    \n",
    "    gamma = trial.suggest_float('gamma', 0.9, 0.9999)  # Discount factor (close to 1 for long-term rewards)\n",
    "    \n",
    "    gae_lambda = trial.suggest_float('gae_lambda', 0.8, 1.0)  # GAE lambda (trade-off bias/variance)\n",
    "    \n",
    "    clip_range = trial.suggest_float('clip_range', 0.1, 0.3)  # PPO clipping range\n",
    "    \n",
    "    ent_coef = trial.suggest_float('ent_coef', 0.0001, 0.1, log=True)  # Entropy coefficient (for exploration)\n",
    "    \n",
    "    vf_coef = trial.suggest_float('vf_coef', 0.1, 1.0)  # Value function loss coefficient\n",
    "    \n",
    "    max_grad_norm = trial.suggest_float('max_grad_norm', 0.3, 5.0)  # Gradient clipping\n",
    "    \n",
    "    target_kl = trial.suggest_float('target_kl', 0.01, 0.2)  # KL divergence target\n",
    "    \n",
    "    n_epochs = trial.suggest_int('n_epochs', 3, 10)  # PPO update epochs per batch\n",
    "    \n",
    "    activation_fn = trial.suggest_categorical('activation_fn', ['tanh', 'relu'])\n",
    "    \n",
    "    net_arch = trial.suggest_categorical('net_arch', ['tiny', 'small'])\n",
    "    \n",
    "    # Convert architecture choices\n",
    "    net_arch = [128, 128] if net_arch == 'tiny' else [256, 256, 256]\n",
    "    \n",
    "    activation_fn = {'tanh': nn.Tanh, 'relu': nn.ReLU}[activation_fn]\n",
    "    \n",
    "    # Store gamma value in Optuna logs\n",
    "    trial.set_user_attr('gamma', gamma)\n",
    "\n",
    "    return {\n",
    "        'n_steps': n_steps,\n",
    "        'batch_size': batch_size,\n",
    "        'gamma': gamma,\n",
    "        'gae_lambda': gae_lambda,\n",
    "        'learning_rate': learning_rate,\n",
    "        'clip_range': clip_range,\n",
    "        'ent_coef': ent_coef,\n",
    "        'vf_coef': vf_coef,\n",
    "        'max_grad_norm': max_grad_norm,\n",
    "        'target_kl': target_kl,\n",
    "        'n_epochs': n_epochs,\n",
    "        'policy_kwargs': {\n",
    "            'net_arch': net_arch,\n",
    "            'activation_fn': activation_fn\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb33df3-8862-42b2-ada4-a0256d9d8f72",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class TrialEvalCallback(EvalCallback):\n",
    "    \"\"\"\n",
    "    Callback used for evaluating and reporting a trial.\n",
    "    \n",
    "    :param eval_env: Evaluation environement\n",
    "    :param trial: Optuna trial object\n",
    "    :param n_eval_episodes: Number of evaluation episodes\n",
    "    :param eval_freq:   Evaluate the agent every ``eval_freq`` call of the callback.\n",
    "    :param deterministic: Whether the evaluation should\n",
    "        use a stochastic or deterministic policy.\n",
    "    :param verbose:\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_env: gym.Env,\n",
    "        trial: optuna.Trial,\n",
    "        n_eval_episodes: int = 5,\n",
    "        eval_freq: int = 10000,\n",
    "        deterministic: bool = True,\n",
    "        verbose: int = 0,\n",
    "    ):\n",
    "\n",
    "        super().__init__(\n",
    "            eval_env=eval_env,\n",
    "            n_eval_episodes=n_eval_episodes,\n",
    "            eval_freq=eval_freq,\n",
    "            deterministic=deterministic,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        self.trial = trial\n",
    "        self.eval_idx = 0\n",
    "        self.is_pruned = False\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
    "            # Evaluate policy (done in the parent class)\n",
    "            super()._on_step()\n",
    "            self.eval_idx += 1\n",
    "            # Send report to Optuna\n",
    "            self.trial.report(self.last_mean_reward, self.eval_idx)\n",
    "            # Prune trial if need\n",
    "            if self.trial.should_prune():\n",
    "                self.is_pruned = True\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5471099b-c248-4f2d-b0df-a7c97c8171fc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function using by Optuna to evaluate\n",
    "    one configuration (i.e., one set of hyperparameters).\n",
    "\n",
    "    Given a trial object, it will sample hyperparameters,\n",
    "    evaluate it and report the result (mean episodic reward after training)\n",
    "\n",
    "    :param trial: Optuna trial object\n",
    "    :return: Mean episodic reward after training\n",
    "    \"\"\"\n",
    "\n",
    "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
    "\n",
    "    # 1. Sample hyperparameters and update the keyword arguments\n",
    "    kwargs.update(**sample_ppo_params(trial))\n",
    "    print(kwargs)\n",
    "    # Create the RL model\n",
    "    model = PPO(device='cpu', verbose=1, **kwargs)\n",
    "    # Create eval envs\n",
    "    eval_envs = make_vec_env(ENV_ID, n_envs=N_EVAL_ENVS)\n",
    "\n",
    "    eval_callback = TrialEvalCallback(eval_envs, trial, N_EVAL_EPISODES, EVAL_FREQ, deterministic=True, verbose=0)\n",
    "\n",
    "    nan_encountered = False\n",
    "    try:\n",
    "        # Train the model\n",
    "        model.learn(N_TIMESTEPS, callback=eval_callback, progress_bar=True)\n",
    "    except AssertionError as e:\n",
    "        # Sometimes, random hyperparams can generate NaN\n",
    "        print(e)\n",
    "        nan_encountered = True\n",
    "    finally:\n",
    "        # Free memory\n",
    "        model.env.close()\n",
    "        eval_envs.close()\n",
    "\n",
    "    # Tell the optimizer that the trial failed\n",
    "    if nan_encountered:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    if eval_callback.is_pruned:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return eval_callback.last_mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd13ee70-42af-4ab4-a7d0-9873df79a065",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Set pytorch num threads to 1 for faster training\n",
    "torch.set_num_threads(1)\n",
    "# Select the sampler, can be random, TPESampler, CMAES, ...\n",
    "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
    "# Do not prune before 1/3 of the max budget is used\n",
    "pruner = MedianPruner(\n",
    "    n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS // 3\n",
    ")\n",
    "# Create the study and start the hyperparameter optimization\n",
    "study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
    "\n",
    "try:\n",
    "    study.optimize(objective, n_trials=N_TRIALS, n_jobs=N_JOBS, timeout=TIMEOUT)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"  Value: {trial.value}\")\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "print(\"  User attrs:\")\n",
    "for key, value in trial.user_attrs.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# Write report\n",
    "study.trials_dataframe().to_csv(\"study_results_ppo_marineenv.csv\")\n",
    "\n",
    "fig1 = plot_optimization_history(study)\n",
    "fig2 = plot_param_importances(study)\n",
    "\n",
    "fig1.show()\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c1bef0-7e94-4b1f-abe8-6e917fb7a917",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "def make_env():\n",
    "    env = gym.make('MarineEnv-v0', render_mode='rgb_array', continuous=True, max_episode_steps=400)\n",
    "    env = Monitor(env)  # âœ… Apply Monitor FIRST before vectorization\n",
    "    return env\n",
    "\n",
    "# Wrap it in `DummyVecEnv` FIRST\n",
    "env = DummyVecEnv([make_env])  \n",
    "\n",
    "# Now apply normalization\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceee0548-ec75-47e1-afc1-09c26ce4ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MarineEnv-v0', render_mode='rgb_array', continuous=True, max_episode_steps=400, training_stage=1, timescale = 1/3)\n",
    "# vec_env = make_vec_env('MarineEnv-v0', n_envs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3375503c-fcdc-4603-9365-e07a4e7bf91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = { \n",
    "    'clip_range': 0.3,\n",
    "    'ent_coef': 0.005,\n",
    "    'gamma': 0.99, \n",
    "    'learning_rate': 1e-4, \n",
    "    'max_grad_norm': 0.99, \n",
    "    'policy_kwargs': {'net_arch': [128, 128], 'activation_fn': torch.nn.Tanh},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6413b289-fc9b-4df1-a806-7d1dc1a33333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\n",
    "    policy='MlpPolicy',\n",
    "    env=env,\n",
    "    verbose=1,\n",
    "    device='cpu', \n",
    "    tensorboard_log='./stage_1_tensorboard_logs/',\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "947167ce-ade1-4036-a3bf-356ae7b9f00a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./stage_1_tensorboard_logs/PPO_18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd4bbfbaff94ba6b714d77c6867d4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 148      |\n",
      "|    ep_rew_mean     | -363     |\n",
      "| time/              |          |\n",
      "|    fps             | 1432     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 155         |\n",
      "|    ep_rew_mean          | -331        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 799         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011109567 |\n",
      "|    clip_fraction        | 0.0228      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | -0.00988    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 686         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 1.45e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 162         |\n",
      "|    ep_rew_mean          | -297        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 843         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017944211 |\n",
      "|    clip_fraction        | 0.0462      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.00621     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 624         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 1.19e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | -257        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 792         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018087897 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.0304      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 584         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 0.989       |\n",
      "|    value_loss           | 976         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 170         |\n",
      "|    ep_rew_mean          | -182        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 788         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013251528 |\n",
      "|    clip_fraction        | 0.0455      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.81       |\n",
      "|    explained_variance   | 0.0605      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 408         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 0.985       |\n",
      "|    value_loss           | 826         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 155         |\n",
      "|    ep_rew_mean          | -90.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 676         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012706036 |\n",
      "|    clip_fraction        | 0.0337      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 436         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.982       |\n",
      "|    value_loss           | 914         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 146         |\n",
      "|    ep_rew_mean          | -35.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 676         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012493445 |\n",
      "|    clip_fraction        | 0.033       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 562         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 1.26e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 133          |\n",
      "|    ep_rew_mean          | 78.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 665          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089592235 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.3          |\n",
      "|    entropy_loss         | -2.78        |\n",
      "|    explained_variance   | 0.326        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 605          |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00979     |\n",
      "|    std                  | 0.972        |\n",
      "|    value_loss           | 1.32e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 124         |\n",
      "|    ep_rew_mean          | 182         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 660         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012808149 |\n",
      "|    clip_fraction        | 0.0374      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.78       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 556         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    std                  | 0.968       |\n",
      "|    value_loss           | 1.29e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 107         |\n",
      "|    ep_rew_mean          | 236         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010797389 |\n",
      "|    clip_fraction        | 0.0231      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 666         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    std                  | 0.966       |\n",
      "|    value_loss           | 1.41e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 103         |\n",
      "|    ep_rew_mean          | 255         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 687         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014094973 |\n",
      "|    clip_fraction        | 0.0528      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 653         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 0.96        |\n",
      "|    value_loss           | 1.38e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 275         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 708         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014801849 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 551         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 0.954       |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 287         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010774351 |\n",
      "|    clip_fraction        | 0.029       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 773         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 0.952       |\n",
      "|    value_loss           | 1.43e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 99.1         |\n",
      "|    ep_rew_mean          | 285          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 745          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109757185 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.3          |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 565          |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.01        |\n",
      "|    std                  | 0.953        |\n",
      "|    value_loss           | 1.3e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 97.7        |\n",
      "|    ep_rew_mean          | 285         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 760         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010175984 |\n",
      "|    clip_fraction        | 0.0351      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.73       |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 492         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00905    |\n",
      "|    std                  | 0.948       |\n",
      "|    value_loss           | 1.04e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.8        |\n",
      "|    ep_rew_mean          | 286         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 774         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013661303 |\n",
      "|    clip_fraction        | 0.043       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 432         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 0.938       |\n",
      "|    value_loss           | 1.01e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 94.7        |\n",
      "|    ep_rew_mean          | 284         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 787         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009890515 |\n",
      "|    clip_fraction        | 0.0283      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.7        |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 431         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00874    |\n",
      "|    std                  | 0.931       |\n",
      "|    value_loss           | 997         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 92.2         |\n",
      "|    ep_rew_mean          | 285          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 793          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0106419735 |\n",
      "|    clip_fraction        | 0.0374       |\n",
      "|    clip_range           | 0.3          |\n",
      "|    entropy_loss         | -2.69        |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 369          |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00999     |\n",
      "|    std                  | 0.93         |\n",
      "|    value_loss           | 976          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.3        |\n",
      "|    ep_rew_mean          | 293         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 745         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017755812 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.69       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 331         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 0.929       |\n",
      "|    value_loss           | 921         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 91.5        |\n",
      "|    ep_rew_mean          | 293         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 755         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009639664 |\n",
      "|    clip_fraction        | 0.0216      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.68       |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 419         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.925       |\n",
      "|    value_loss           | 900         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 90.1        |\n",
      "|    ep_rew_mean          | 291         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 766         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012108297 |\n",
      "|    clip_fraction        | 0.0519      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.67       |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 303         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 0.922       |\n",
      "|    value_loss           | 845         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 88.8        |\n",
      "|    ep_rew_mean          | 290         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 776         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016411379 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.66       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 348         |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 0.918       |\n",
      "|    value_loss           | 813         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 87.6        |\n",
      "|    ep_rew_mean          | 287         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 785         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012434501 |\n",
      "|    clip_fraction        | 0.0466      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 306         |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.905       |\n",
      "|    value_loss           | 664         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 87.7         |\n",
      "|    ep_rew_mean          | 291          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 794          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117279105 |\n",
      "|    clip_fraction        | 0.045        |\n",
      "|    clip_range           | 0.3          |\n",
      "|    entropy_loss         | -2.63        |\n",
      "|    explained_variance   | 0.235        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 296          |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    std                  | 0.904        |\n",
      "|    value_loss           | 636          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 88.9        |\n",
      "|    ep_rew_mean          | 294         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 803         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011295909 |\n",
      "|    clip_fraction        | 0.0449      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 242         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 0.9         |\n",
      "|    value_loss           | 543         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 87.3        |\n",
      "|    ep_rew_mean          | 285         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 810         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012448361 |\n",
      "|    clip_fraction        | 0.0395      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 230         |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 0.895       |\n",
      "|    value_loss           | 558         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 87          |\n",
      "|    ep_rew_mean          | 283         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 818         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014087699 |\n",
      "|    clip_fraction        | 0.0396      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.6        |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 185         |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 0.889       |\n",
      "|    value_loss           | 416         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 86.8        |\n",
      "|    ep_rew_mean          | 288         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 825         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011600139 |\n",
      "|    clip_fraction        | 0.036       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.59       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 231         |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00768    |\n",
      "|    std                  | 0.887       |\n",
      "|    value_loss           | 461         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 92.1        |\n",
      "|    ep_rew_mean          | 300         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 832         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015294222 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 184         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 0.878       |\n",
      "|    value_loss           | 523         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 93.5        |\n",
      "|    ep_rew_mean          | 307         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 838         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012742854 |\n",
      "|    clip_fraction        | 0.0318      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.56       |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 161         |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    std                  | 0.874       |\n",
      "|    value_loss           | 413         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.1        |\n",
      "|    ep_rew_mean          | 318         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 844         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017095517 |\n",
      "|    clip_fraction        | 0.0638      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.55       |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 199         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 0.871       |\n",
      "|    value_loss           | 408         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.6        |\n",
      "|    ep_rew_mean          | 318         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 850         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010324649 |\n",
      "|    clip_fraction        | 0.0417      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.54       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 261         |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    std                  | 0.869       |\n",
      "|    value_loss           | 513         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 94.8        |\n",
      "|    ep_rew_mean          | 315         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 854         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016273316 |\n",
      "|    clip_fraction        | 0.056       |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 201         |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.864       |\n",
      "|    value_loss           | 462         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 96.6        |\n",
      "|    ep_rew_mean          | 312         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 827         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009598304 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 192         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    std                  | 0.863       |\n",
      "|    value_loss           | 394         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 93.2        |\n",
      "|    ep_rew_mean          | 306         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 832         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013011755 |\n",
      "|    clip_fraction        | 0.0398      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.52       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0096     |\n",
      "|    std                  | 0.859       |\n",
      "|    value_loss           | 264         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 94.3        |\n",
      "|    ep_rew_mean          | 311         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 837         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011239931 |\n",
      "|    clip_fraction        | 0.0348      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.51       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 185         |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    std                  | 0.86        |\n",
      "|    value_loss           | 387         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 98.1        |\n",
      "|    ep_rew_mean          | 321         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 842         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016106669 |\n",
      "|    clip_fraction        | 0.0504      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.51       |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 189         |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 0.857       |\n",
      "|    value_loss           | 423         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95.8        |\n",
      "|    ep_rew_mean          | 315         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 847         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012090902 |\n",
      "|    clip_fraction        | 0.0392      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.5        |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 155         |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    std                  | 0.851       |\n",
      "|    value_loss           | 325         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 93.3        |\n",
      "|    ep_rew_mean          | 317         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 852         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015284986 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.49       |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 97.5        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 0.849       |\n",
      "|    value_loss           | 225         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 96.7        |\n",
      "|    ep_rew_mean          | 320         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 856         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011807075 |\n",
      "|    clip_fraction        | 0.0362      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.48       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 173         |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00948    |\n",
      "|    std                  | 0.842       |\n",
      "|    value_loss           | 376         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 95.3       |\n",
      "|    ep_rew_mean          | 319        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 861        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 97         |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01334857 |\n",
      "|    clip_fraction        | 0.0381     |\n",
      "|    clip_range           | 0.3        |\n",
      "|    entropy_loss         | -2.46      |\n",
      "|    explained_variance   | 0.601      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 103        |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.00752   |\n",
      "|    std                  | 0.837      |\n",
      "|    value_loss           | 226        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 93.6        |\n",
      "|    ep_rew_mean          | 316         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 864         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008236276 |\n",
      "|    clip_fraction        | 0.0228      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.46       |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 157         |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    std                  | 0.835       |\n",
      "|    value_loss           | 297         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 91.1        |\n",
      "|    ep_rew_mean          | 316         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 868         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011769316 |\n",
      "|    clip_fraction        | 0.0419      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.46       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 0.839       |\n",
      "|    value_loss           | 234         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 91.8        |\n",
      "|    ep_rew_mean          | 310         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 869         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012966896 |\n",
      "|    clip_fraction        | 0.0515      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.45       |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 95.2        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    std                  | 0.833       |\n",
      "|    value_loss           | 259         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 93.4         |\n",
      "|    ep_rew_mean          | 311          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 872          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 105          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070323544 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.3          |\n",
      "|    entropy_loss         | -2.44        |\n",
      "|    explained_variance   | 0.755        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 85           |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    std                  | 0.83         |\n",
      "|    value_loss           | 201          |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 95.2     |\n",
      "|    ep_rew_mean          | 314      |\n",
      "| time/                   |          |\n",
      "|    fps                  | 869      |\n",
      "|    iterations           | 46       |\n",
      "|    time_elapsed         | 108      |\n",
      "|    total_timesteps      | 94208    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.013089 |\n",
      "|    clip_fraction        | 0.041    |\n",
      "|    clip_range           | 0.3      |\n",
      "|    entropy_loss         | -2.43    |\n",
      "|    explained_variance   | 0.714    |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 63.9     |\n",
      "|    n_updates            | 450      |\n",
      "|    policy_gradient_loss | -0.0101  |\n",
      "|    std                  | 0.824    |\n",
      "|    value_loss           | 151      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | 325         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 859         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013005741 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.42       |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 81.3        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    std                  | 0.822       |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | 328         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 842         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010566292 |\n",
      "|    clip_fraction        | 0.0266      |\n",
      "|    clip_range           | 0.3         |\n",
      "|    entropy_loss         | -2.41       |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 85.2        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    std                  | 0.816       |\n",
      "|    value_loss           | 230         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 101       |\n",
      "|    ep_rew_mean          | 334       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 49        |\n",
      "|    time_elapsed         | 118       |\n",
      "|    total_timesteps      | 100352    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0146303 |\n",
      "|    clip_fraction        | 0.0491    |\n",
      "|    clip_range           | 0.3       |\n",
      "|    entropy_loss         | -2.39     |\n",
      "|    explained_variance   | 0.767     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 93.2      |\n",
      "|    n_updates            | 480       |\n",
      "|    policy_gradient_loss | -0.0113   |\n",
      "|    std                  | 0.812     |\n",
      "|    value_loss           | 190       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f0efca94b50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=(1e5), progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "466d533e-0a5d-4c2d-aaf5-467bad256d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 534.38, Std: 214.66\n"
     ]
    }
   ],
   "source": [
    "mean, std = evaluate_policy(model=model, env=env, n_eval_episodes=10, deterministic=True)\n",
    "print(f'Mean: {mean:.2f}, Std: {std:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22985742-c740-42fa-8382-f042d32ddb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./stage_1_tensorboard_logs/ --host=0.0.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcce986e-7b91-4254-a25c-42bc26d7954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save environment normalization stats\n",
    "# env.save(\"ppo_normalized_env.pkl\")\n",
    "model.save(\"ppo_marine_stage_2\")\n",
    "# model = model.load('ppo_marine_stage_1.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e5042a-6ba5-4092-b202-5b02a635b376",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "env = VecNormalize.load(\"ppo_normalized_env.pkl\", env)\n",
    "\n",
    "# Disable reward normalization for evaluation\n",
    "env.training = False\n",
    "env.norm_reward = False\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "obs = env.reset()\n",
    "for _ in range(100):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, dones, _ = env.step(action)\n",
    "\n",
    "    # âœ… Ensure env.get_images() is not empty\n",
    "    images = env.get_images()\n",
    "    if images and images[0] is not None:\n",
    "        frame = images[0]\n",
    "        \n",
    "        # âœ… Ensure the frame has valid dimensions before displaying\n",
    "        if frame.shape[0] > 0 and frame.shape[1] > 0:\n",
    "            cv2.imshow(\"PPO MarineEnv Evaluation\", frame)\n",
    "            cv2.waitKey(1)  # Display for 1ms\n",
    "        else:\n",
    "            print(\"Warning: Received an empty frame from env.get_images()\")\n",
    "\n",
    "    if dones:\n",
    "        break\n",
    "\n",
    "env.close()\n",
    "cv2.destroyAllWindows()  # Close display window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec1768e6-1c27-4e5b-9ffc-66d9743dad97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[229.82985    15.980538    5.7468853  21.577065   44.42689    21.577065\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.       ]\n",
      "===========================\n",
      "[249.82985   16.224787   5.501649  20.345348  25.592318  20.577065\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.      ]\n",
      "===========================\n",
      "[269.82983    16.490387    5.2280016  19.021997    5.886031   19.577065\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.       ]\n",
      "===========================\n",
      "[289.82983    16.613306    4.9597507  17.912453  -14.894509   18.577065\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.       ]\n",
      "===========================\n",
      "[269.82983    16.516487    4.685447   17.020983    5.4052396  17.577065\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.       ]\n",
      "===========================\n",
      "[289.82983   16.62566    4.417666  15.942822 -15.500995  16.577065\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.      ]\n",
      "===========================\n",
      "[269.82983    16.53464     4.142809   15.033199    4.798162   15.5770645\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.       ]\n",
      "===========================\n",
      "[289.82983    16.62425     3.8759348  13.988968  -16.276632   14.5770645\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.       ]\n",
      "===========================\n",
      "[269.82983    16.538565    3.600733   13.063044    4.008381   13.5770645\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.       ]\n",
      "===========================\n",
      "[289.2274     16.601875    3.3345857  12.051358  -16.651796   12.5770645\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.       ]\n",
      "===========================\n",
      "[269.2274     16.51823     3.0596087  11.113571    3.649492   11.5770645\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.       ]\n",
      "===========================\n",
      "[287.1382     16.569027    2.792618   10.112669  -15.658148   10.5770645\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.       ]\n",
      "===========================\n",
      "[267.1382     16.480066    2.5186398   9.169768    4.8152037   9.5770645\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.       ]\n",
      "===========================\n",
      "[287.1382     16.568052    2.2531297   8.159545  -17.02564     8.5770645\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.       ]\n",
      "===========================\n",
      "[267.1382     16.48587     1.9786016   7.2010813   3.3874881   7.5770645\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.       ]\n",
      "===========================\n",
      "[282.70874    16.519876    1.7102784   6.211711  -14.131305    6.5770645\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.       ]\n",
      "===========================\n",
      "[262.70874    16.420153    1.4381325   5.255003    6.9843497   5.5770645\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.       ]\n",
      "===========================\n",
      "[282.70874    16.558174    1.170725    4.242225  -16.060946    4.5770645\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.       ]\n",
      "===========================\n",
      "[262.70874    16.4729      0.8968391   3.2665982   5.1448526   3.5770645\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.       ]\n",
      "===========================\n",
      "[281.84894     16.545036     0.63262326   2.2941864  -20.050556\n",
      "   2.5770645    0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.        ]\n",
      "===========================\n",
      "[ 2.6184894e+02  1.6467346e+01  3.5798261e-01  1.3043362e+00\n",
      " -8.9369968e-02  1.5770645e+00  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      "===========================\n",
      "[2.5964798e+02 1.6386375e+01 8.5472964e-02 3.1296599e-01 8.8773537e+00\n",
      " 5.7706451e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00]\n",
      "172.88902693986893\n",
      "172.88902693986893\n",
      "[ 2.6184894e+02  1.6467346e+01  3.5798261e-01  1.3043362e+00\n",
      " -8.9369968e-02  1.5770645e+00  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MarineEnv-v0', render_mode='human', continuous=True, training_stage=1, timescale = 1)\n",
    "state, _ = env.reset()\n",
    "print(state)\n",
    "episode_rewards = 0 \n",
    "# flatten_state = flatten(env.observation_space, state)\n",
    "# state = torch.tensor(flatten_state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "for _ in range(400):\n",
    "    action = model.predict(state, deterministic=True)\n",
    "    # print(action)\n",
    "    # observation, reward, terminated, truncated, info = env.step((0, 0))\n",
    "    observation, reward, terminated, truncated, info = env.step(action[0])\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "    episode_rewards += reward\n",
    "    print('===========================')\n",
    "    print(observation)\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        print(episode_rewards)\n",
    "        break\n",
    "\n",
    "    state = observation\n",
    "        \n",
    "print(episode_rewards)\n",
    "print(state)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfc754b-7691-48d8-8184-2d523c8e5769",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537c49c8-5818-46df-841f-7fb5413e55c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee9957-a3e7-40cf-8041-f5deb2ce3e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9effaf34-ba22-4905-811d-3d2c22e1d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(state)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf689ce1-0d17-4780-9ad0-2ffe02b9bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfdcc56-f86c-4cc3-bace-4dc3def3464d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
