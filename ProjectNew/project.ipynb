{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b02451-c710-4547-8cac-8f795470bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade grpcio grpcio-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8799ec51-d0be-4c4f-a4ad-4e8ad539f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605a33c7-17ed-42c1-9e6e-be50b0addb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 19:45:36.611285: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-25 19:45:36.626758: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737834336.644770    5604 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737834336.651552    5604 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-25 19:45:36.672376: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gymnasium.spaces.utils import flatten\n",
    "from gymnasium.envs.registration import register, registry\n",
    "import time\n",
    "import numpy as np\n",
    "import pygame\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Any, Dict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorboard\n",
    "\n",
    "from stable_baselines3 import PPO, A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import VecNormalize, DummyVecEnv\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6482d68a-fce7-40e6-8d5a-275862ba21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'MarineEnv-v0' not in registry:\n",
    "    register(\n",
    "        id='MarineEnv-v0',\n",
    "        entry_point='environments:MarineEnv',  # String reference to the class\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c1337d-61df-4e2c-ae20-98ec70f98b2e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3cfe3-f53f-4a9e-b7f9-f5954238fcf6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "N_TRIALS = 100  # Maximum number of trials\n",
    "N_JOBS = 1 # Number of jobs to run in parallel\n",
    "N_STARTUP_TRIALS = 5  # Stop random sampling after N_STARTUP_TRIALS\n",
    "N_EVALUATIONS = 2  # Number of evaluations during the training\n",
    "N_TIMESTEPS = int(2e4)  # Training budget\n",
    "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS)\n",
    "N_EVAL_ENVS = 10\n",
    "N_EVAL_EPISODES = 10\n",
    "TIMEOUT = int(60 * 15)  # 15 minutes\n",
    "\n",
    "ENV_ID = 'MarineEnv-v0'\n",
    "\n",
    "DEFAULT_HYPERPARAMS = {\n",
    "    \"policy\": \"MlpPolicy\",\n",
    "    \"env\": ENV_ID,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3bf52b-6b8c-4b0b-9e54-2fddb2790918",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def sample_ppo_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
    "    \n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1, log=True)  # Learning rate (log scale)\n",
    "    \n",
    "    n_steps = 2 ** trial.suggest_int('n_steps', 7, 12)  # Number of steps per update (512-4096)\n",
    "    \n",
    "    batch_size = 2 ** trial.suggest_int('batch_size', 5, 10)  # Minibatch size (32-1024)\n",
    "    \n",
    "    gamma = trial.suggest_float('gamma', 0.9, 0.9999)  # Discount factor (close to 1 for long-term rewards)\n",
    "    \n",
    "    gae_lambda = trial.suggest_float('gae_lambda', 0.8, 1.0)  # GAE lambda (trade-off bias/variance)\n",
    "    \n",
    "    clip_range = trial.suggest_float('clip_range', 0.1, 0.3)  # PPO clipping range\n",
    "    \n",
    "    ent_coef = trial.suggest_float('ent_coef', 0.0001, 0.1, log=True)  # Entropy coefficient (for exploration)\n",
    "    \n",
    "    vf_coef = trial.suggest_float('vf_coef', 0.1, 1.0)  # Value function loss coefficient\n",
    "    \n",
    "    max_grad_norm = trial.suggest_float('max_grad_norm', 0.3, 5.0)  # Gradient clipping\n",
    "    \n",
    "    target_kl = trial.suggest_float('target_kl', 0.01, 0.2)  # KL divergence target\n",
    "    \n",
    "    n_epochs = trial.suggest_int('n_epochs', 3, 10)  # PPO update epochs per batch\n",
    "    \n",
    "    activation_fn = trial.suggest_categorical('activation_fn', ['tanh', 'relu'])\n",
    "    \n",
    "    net_arch = trial.suggest_categorical('net_arch', ['tiny', 'small'])\n",
    "    \n",
    "    # Convert architecture choices\n",
    "    net_arch = [128, 128] if net_arch == 'tiny' else [256, 256, 256]\n",
    "    \n",
    "    activation_fn = {'tanh': nn.Tanh, 'relu': nn.ReLU}[activation_fn]\n",
    "    \n",
    "    # Store gamma value in Optuna logs\n",
    "    trial.set_user_attr('gamma', gamma)\n",
    "\n",
    "    return {\n",
    "        'n_steps': n_steps,\n",
    "        'batch_size': batch_size,\n",
    "        'gamma': gamma,\n",
    "        'gae_lambda': gae_lambda,\n",
    "        'learning_rate': learning_rate,\n",
    "        'clip_range': clip_range,\n",
    "        'ent_coef': ent_coef,\n",
    "        'vf_coef': vf_coef,\n",
    "        'max_grad_norm': max_grad_norm,\n",
    "        'target_kl': target_kl,\n",
    "        'n_epochs': n_epochs,\n",
    "        'policy_kwargs': {\n",
    "            'net_arch': net_arch,\n",
    "            'activation_fn': activation_fn\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb33df3-8862-42b2-ada4-a0256d9d8f72",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class TrialEvalCallback(EvalCallback):\n",
    "    \"\"\"\n",
    "    Callback used for evaluating and reporting a trial.\n",
    "    \n",
    "    :param eval_env: Evaluation environement\n",
    "    :param trial: Optuna trial object\n",
    "    :param n_eval_episodes: Number of evaluation episodes\n",
    "    :param eval_freq:   Evaluate the agent every ``eval_freq`` call of the callback.\n",
    "    :param deterministic: Whether the evaluation should\n",
    "        use a stochastic or deterministic policy.\n",
    "    :param verbose:\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_env: gym.Env,\n",
    "        trial: optuna.Trial,\n",
    "        n_eval_episodes: int = 5,\n",
    "        eval_freq: int = 10000,\n",
    "        deterministic: bool = True,\n",
    "        verbose: int = 0,\n",
    "    ):\n",
    "\n",
    "        super().__init__(\n",
    "            eval_env=eval_env,\n",
    "            n_eval_episodes=n_eval_episodes,\n",
    "            eval_freq=eval_freq,\n",
    "            deterministic=deterministic,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        self.trial = trial\n",
    "        self.eval_idx = 0\n",
    "        self.is_pruned = False\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
    "            # Evaluate policy (done in the parent class)\n",
    "            super()._on_step()\n",
    "            self.eval_idx += 1\n",
    "            # Send report to Optuna\n",
    "            self.trial.report(self.last_mean_reward, self.eval_idx)\n",
    "            # Prune trial if need\n",
    "            if self.trial.should_prune():\n",
    "                self.is_pruned = True\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5471099b-c248-4f2d-b0df-a7c97c8171fc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function using by Optuna to evaluate\n",
    "    one configuration (i.e., one set of hyperparameters).\n",
    "\n",
    "    Given a trial object, it will sample hyperparameters,\n",
    "    evaluate it and report the result (mean episodic reward after training)\n",
    "\n",
    "    :param trial: Optuna trial object\n",
    "    :return: Mean episodic reward after training\n",
    "    \"\"\"\n",
    "\n",
    "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
    "\n",
    "    # 1. Sample hyperparameters and update the keyword arguments\n",
    "    kwargs.update(**sample_ppo_params(trial))\n",
    "    print(kwargs)\n",
    "    # Create the RL model\n",
    "    model = PPO(device='cpu', verbose=1, **kwargs)\n",
    "    # Create eval envs\n",
    "    eval_envs = make_vec_env(ENV_ID, n_envs=N_EVAL_ENVS)\n",
    "\n",
    "    eval_callback = TrialEvalCallback(eval_envs, trial, N_EVAL_EPISODES, EVAL_FREQ, deterministic=True, verbose=0)\n",
    "\n",
    "    nan_encountered = False\n",
    "    try:\n",
    "        # Train the model\n",
    "        model.learn(N_TIMESTEPS, callback=eval_callback, progress_bar=True)\n",
    "    except AssertionError as e:\n",
    "        # Sometimes, random hyperparams can generate NaN\n",
    "        print(e)\n",
    "        nan_encountered = True\n",
    "    finally:\n",
    "        # Free memory\n",
    "        model.env.close()\n",
    "        eval_envs.close()\n",
    "\n",
    "    # Tell the optimizer that the trial failed\n",
    "    if nan_encountered:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    if eval_callback.is_pruned:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return eval_callback.last_mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd13ee70-42af-4ab4-a7d0-9873df79a065",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Set pytorch num threads to 1 for faster training\n",
    "torch.set_num_threads(1)\n",
    "# Select the sampler, can be random, TPESampler, CMAES, ...\n",
    "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
    "# Do not prune before 1/3 of the max budget is used\n",
    "pruner = MedianPruner(\n",
    "    n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS // 3\n",
    ")\n",
    "# Create the study and start the hyperparameter optimization\n",
    "study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
    "\n",
    "try:\n",
    "    study.optimize(objective, n_trials=N_TRIALS, n_jobs=N_JOBS, timeout=TIMEOUT)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"  Value: {trial.value}\")\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "print(\"  User attrs:\")\n",
    "for key, value in trial.user_attrs.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# Write report\n",
    "study.trials_dataframe().to_csv(\"study_results_ppo_marineenv.csv\")\n",
    "\n",
    "fig1 = plot_optimization_history(study)\n",
    "fig2 = plot_param_importances(study)\n",
    "\n",
    "fig1.show()\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c1bef0-7e94-4b1f-abe8-6e917fb7a917",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "def make_env():\n",
    "    env = gym.make('MarineEnv-v0', render_mode='rgb_array', continuous=True, max_episode_steps=400)\n",
    "    env = Monitor(env)  # ✅ Apply Monitor FIRST before vectorization\n",
    "    return env\n",
    "\n",
    "# Wrap it in `DummyVecEnv` FIRST\n",
    "env = DummyVecEnv([make_env])  \n",
    "\n",
    "# Now apply normalization\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceee0548-ec75-47e1-afc1-09c26ce4ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MarineEnv-v0', render_mode='rgb_array', continuous=True, max_episode_steps=400)\n",
    "# vec_env = make_vec_env('MarineEnv-v0', n_envs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3375503c-fcdc-4603-9365-e07a4e7bf91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = { \n",
    "    'clip_range': 0.2,\n",
    "    'ent_coef': 0.02,\n",
    "    'gamma': 0.99, \n",
    "    'learning_rate': 1e-4, \n",
    "    'max_grad_norm': 0.99, \n",
    "    'policy_kwargs': {'net_arch': [128, 128], 'activation_fn': torch.nn.Tanh},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6413b289-fc9b-4df1-a806-7d1dc1a33333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\n",
    "    policy='MlpPolicy',\n",
    "    env=env,\n",
    "    verbose=1,\n",
    "    device='cpu', \n",
    "    tensorboard_log='./stage_1_tensorboard_logs/',\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "947167ce-ade1-4036-a3bf-356ae7b9f00a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./stage_1_tensorboard_logs/PPO_8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5575e5a0fba64472a2171c1bb226d02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 141      |\n",
      "|    ep_rew_mean     | 403      |\n",
      "| time/              |          |\n",
      "|    fps             | 1185     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 152         |\n",
      "|    ep_rew_mean          | 445         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1017        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008081628 |\n",
      "|    clip_fraction        | 0.0657      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.0798      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 292         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 154         |\n",
      "|    ep_rew_mean          | 438         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 985         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009235654 |\n",
      "|    clip_fraction        | 0.0786      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.0119      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 178         |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 373         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 148         |\n",
      "|    ep_rew_mean          | 430         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 971         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010424539 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.0273      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 285         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 148          |\n",
      "|    ep_rew_mean          | 430          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 961          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076119825 |\n",
      "|    clip_fraction        | 0.0619       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0464       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 139          |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00687     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 347          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 149          |\n",
      "|    ep_rew_mean          | 432          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 863          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072678803 |\n",
      "|    clip_fraction        | 0.0667       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0484       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 136          |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00834     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 312          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 150         |\n",
      "|    ep_rew_mean          | 433         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 861         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005758926 |\n",
      "|    clip_fraction        | 0.0469      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 90.5        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 155         |\n",
      "|    ep_rew_mean          | 437         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 864         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004333049 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 98.7        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 283         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 157          |\n",
      "|    ep_rew_mean          | 440          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 864          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076282974 |\n",
      "|    clip_fraction        | 0.0578       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.431        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 65.1         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00792     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 122          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 152         |\n",
      "|    ep_rew_mean          | 432         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 868         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003319283 |\n",
      "|    clip_fraction        | 0.0241      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 75.3        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 150        |\n",
      "|    ep_rew_mean          | 425        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 870        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00509267 |\n",
      "|    clip_fraction        | 0.0385     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.83      |\n",
      "|    explained_variance   | 0.641      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 122        |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.00609   |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 197        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 154         |\n",
      "|    ep_rew_mean          | 431         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 875         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007109844 |\n",
      "|    clip_fraction        | 0.0738      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 75.1        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 158         |\n",
      "|    ep_rew_mean          | 438         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 880         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007936636 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 73          |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00814    |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 156          |\n",
      "|    ep_rew_mean          | 441          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 884          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064706774 |\n",
      "|    clip_fraction        | 0.0478       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 68.2         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00633     |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 204          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 143         |\n",
      "|    ep_rew_mean          | 426         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 889         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007637251 |\n",
      "|    clip_fraction        | 0.0526      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 88.7        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 207         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 149         |\n",
      "|    ep_rew_mean          | 440         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 891         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005739741 |\n",
      "|    clip_fraction        | 0.0511      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 150         |\n",
      "|    ep_rew_mean          | 446         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 894         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008861956 |\n",
      "|    clip_fraction        | 0.0771      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 73.4        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00552    |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 157          |\n",
      "|    ep_rew_mean          | 460          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 897          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067840316 |\n",
      "|    clip_fraction        | 0.0635       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 75.6         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00957     |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 200          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 163         |\n",
      "|    ep_rew_mean          | 477         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 898         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006549947 |\n",
      "|    clip_fraction        | 0.0532      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 37          |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0085     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 161          |\n",
      "|    ep_rew_mean          | 482          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 900          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072142137 |\n",
      "|    clip_fraction        | 0.0442       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 77.6         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.00627     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 186          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 162         |\n",
      "|    ep_rew_mean          | 480         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 901         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005647663 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 231         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 166          |\n",
      "|    ep_rew_mean          | 485          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 902          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052581835 |\n",
      "|    clip_fraction        | 0.0347       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.775        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 50.9         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 174          |\n",
      "|    ep_rew_mean          | 495          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 903          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038442137 |\n",
      "|    clip_fraction        | 0.0415       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.762        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 50.4         |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 170        |\n",
      "|    ep_rew_mean          | 485        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 905        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 54         |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00768173 |\n",
      "|    clip_fraction        | 0.0735     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.84      |\n",
      "|    explained_variance   | 0.846      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 33.7       |\n",
      "|    n_updates            | 530        |\n",
      "|    policy_gradient_loss | -0.0085    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 84.9       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 167          |\n",
      "|    ep_rew_mean          | 482          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 906          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060004494 |\n",
      "|    clip_fraction        | 0.042        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.851        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 42.6         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 164          |\n",
      "|    ep_rew_mean          | 478          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 908          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 58           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047938004 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.874        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 63.5         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 165         |\n",
      "|    ep_rew_mean          | 482         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 906         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005881694 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 75.5        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 167          |\n",
      "|    ep_rew_mean          | 478          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 905          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060873944 |\n",
      "|    clip_fraction        | 0.0444       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.776        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 63.8         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.00796     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 150          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 164        |\n",
      "|    ep_rew_mean          | 476        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 904        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 65         |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00747294 |\n",
      "|    clip_fraction        | 0.0661     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.82      |\n",
      "|    explained_variance   | 0.844      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 22.8       |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.00558   |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 78.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 164        |\n",
      "|    ep_rew_mean          | 482        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 894        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 68         |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00665067 |\n",
      "|    clip_fraction        | 0.0505     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.82      |\n",
      "|    explained_variance   | 0.907      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 40.1       |\n",
      "|    n_updates            | 590        |\n",
      "|    policy_gradient_loss | -0.00482   |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 99.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 161          |\n",
      "|    ep_rew_mean          | 485          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 885          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046378504 |\n",
      "|    clip_fraction        | 0.0517       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.877        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 36.6         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.00562     |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 165          |\n",
      "|    ep_rew_mean          | 497          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 874          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057157963 |\n",
      "|    clip_fraction        | 0.0684       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.884        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 43.7         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.00586     |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 168          |\n",
      "|    ep_rew_mean          | 502          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 866          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070977164 |\n",
      "|    clip_fraction        | 0.0599       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.855        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 48           |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.00736     |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 92.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 172         |\n",
      "|    ep_rew_mean          | 508         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 860         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006600527 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.81       |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 44.1        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 82.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 165          |\n",
      "|    ep_rew_mean          | 490          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 851          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 84           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039791954 |\n",
      "|    clip_fraction        | 0.0433       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.886        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 43.2         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 165          |\n",
      "|    ep_rew_mean          | 491          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 847          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064999266 |\n",
      "|    clip_fraction        | 0.0507       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.886        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 51.1         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.00672     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 94.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 169         |\n",
      "|    ep_rew_mean          | 496         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 841         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007902777 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.81       |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 61.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 175          |\n",
      "|    ep_rew_mean          | 507          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 835          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 93           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084037185 |\n",
      "|    clip_fraction        | 0.0618       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.905        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.00871     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 43.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 176          |\n",
      "|    ep_rew_mean          | 512          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 827          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 96           |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056307227 |\n",
      "|    clip_fraction        | 0.0525       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.875        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 32.8         |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 100          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 175        |\n",
      "|    ep_rew_mean          | 511        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 820        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 99         |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00661347 |\n",
      "|    clip_fraction        | 0.042      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.81      |\n",
      "|    explained_variance   | 0.901      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 26.8       |\n",
      "|    n_updates            | 690        |\n",
      "|    policy_gradient_loss | -0.0076    |\n",
      "|    std                  | 0.994      |\n",
      "|    value_loss           | 106        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 174          |\n",
      "|    ep_rew_mean          | 507          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 815          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 102          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054117474 |\n",
      "|    clip_fraction        | 0.0643       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 36.1         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.008       |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 80.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 176          |\n",
      "|    ep_rew_mean          | 511          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 810          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 106          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069733816 |\n",
      "|    clip_fraction        | 0.0547       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 46.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 181         |\n",
      "|    ep_rew_mean          | 523         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 807         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008410468 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 64.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 185          |\n",
      "|    ep_rew_mean          | 536          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 802          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 112          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069291587 |\n",
      "|    clip_fraction        | 0.053        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 35.4         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    std                  | 0.987        |\n",
      "|    value_loss           | 57.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 183         |\n",
      "|    ep_rew_mean          | 539         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 797         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005701106 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 83.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 178         |\n",
      "|    ep_rew_mean          | 530         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 794         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008357616 |\n",
      "|    clip_fraction        | 0.0704      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    std                  | 0.985       |\n",
      "|    value_loss           | 60.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 176         |\n",
      "|    ep_rew_mean          | 531         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 792         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007234048 |\n",
      "|    clip_fraction        | 0.0584      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 58          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 175          |\n",
      "|    ep_rew_mean          | 527          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 789          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078037507 |\n",
      "|    clip_fraction        | 0.08         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.79        |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.00495     |\n",
      "|    std                  | 0.983        |\n",
      "|    value_loss           | 66.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 177         |\n",
      "|    ep_rew_mean          | 523         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 787         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004706593 |\n",
      "|    clip_fraction        | 0.0475      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.78       |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 60.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f996f8ea750>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=(1e5), progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d533e-0a5d-4c2d-aaf5-467bad256d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = evaluate_policy(model=model, env=env, n_eval_episodes=10, deterministic=True)\n",
    "print(f'Mean: {mean:.2f}, Std: {std:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22985742-c740-42fa-8382-f042d32ddb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a62dcc789b673af7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a62dcc789b673af7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./stage_1_tensorboard_logs/ --host=0.0.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcce986e-7b91-4254-a25c-42bc26d7954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save environment normalization stats\n",
    "# env.save(\"ppo_normalized_env.pkl\")\n",
    "model.save(\"ppo_marine_stage_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57e5042a-6ba5-4092-b202-5b02a635b376",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ppo_normalized_env.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mVecNormalize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mppo_normalized_env.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Disable reward normalization for evaluation\u001b[39;00m\n\u001b[1;32m      4\u001b[0m env\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/vec_normalize.py:317\u001b[0m, in \u001b[0;36mVecNormalize.load\u001b[0;34m(load_path, venv)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(load_path: \u001b[38;5;28mstr\u001b[39m, venv: VecEnv) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVecNormalize\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    310\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m    Loads a saved VecNormalize object.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m    :return:\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file_handler:\n\u001b[1;32m    318\u001b[0m         vec_normalize \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file_handler)\n\u001b[1;32m    319\u001b[0m     vec_normalize\u001b[38;5;241m.\u001b[39mset_venv(venv)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ppo_normalized_env.pkl'"
     ]
    }
   ],
   "source": [
    "env = VecNormalize.load(\"ppo_normalized_env.pkl\", env)\n",
    "\n",
    "# Disable reward normalization for evaluation\n",
    "env.training = False\n",
    "env.norm_reward = False\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "obs = env.reset()\n",
    "for _ in range(100):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, dones, _ = env.step(action)\n",
    "\n",
    "    # ✅ Ensure env.get_images() is not empty\n",
    "    images = env.get_images()\n",
    "    if images and images[0] is not None:\n",
    "        frame = images[0]\n",
    "        \n",
    "        # ✅ Ensure the frame has valid dimensions before displaying\n",
    "        if frame.shape[0] > 0 and frame.shape[1] > 0:\n",
    "            cv2.imshow(\"PPO MarineEnv Evaluation\", frame)\n",
    "            cv2.waitKey(1)  # Display for 1ms\n",
    "        else:\n",
    "            print(\"Warning: Received an empty frame from env.get_images()\")\n",
    "\n",
    "    if dones:\n",
    "        break\n",
    "\n",
    "env.close()\n",
    "cv2.destroyAllWindows()  # Close display window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec1768e6-1c27-4e5b-9ffc-66d9743dad97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 347.4082      8.376266   10.969941   78.57875  -130.49861    78.57875\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.      ]\n",
      "413.3490271508691\n",
      "413.3490271508691\n",
      "[218.841       10.996329     0.22503842   1.227892    -7.6489563\n",
      "   6.912073     0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.        ]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MarineEnv-v0', render_mode='human', continuous=True)\n",
    "state, _ = env.reset()\n",
    "print(state)\n",
    "episode_rewards = 0 \n",
    "# flatten_state = flatten(env.observation_space, state)\n",
    "# state = torch.tensor(flatten_state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "for _ in range(400):\n",
    "    action = model.predict(state, deterministic=True)\n",
    "    # print(action)\n",
    "    observation, reward, terminated, truncated, info = env.step(action[0])\n",
    "    env.render()\n",
    "    time.sleep(0.01)\n",
    "    episode_rewards += reward\n",
    "    # print('===========================')\n",
    "    # print(observation)\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        print(episode_rewards)\n",
    "        break\n",
    "\n",
    "    state = observation\n",
    "        \n",
    "print(episode_rewards)\n",
    "print(state)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dfc754b-7691-48d8-8184-2d523c8e5769",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537c49c8-5818-46df-841f-7fb5413e55c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee9957-a3e7-40cf-8041-f5deb2ce3e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9effaf34-ba22-4905-811d-3d2c22e1d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(state)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf689ce1-0d17-4780-9ad0-2ffe02b9bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfdcc56-f86c-4cc3-bace-4dc3def3464d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
