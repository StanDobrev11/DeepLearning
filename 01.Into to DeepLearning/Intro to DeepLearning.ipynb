{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "source": [
    "%matplotlib inline"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "257e9e66-0b74-4e7b-89e9-e1eb86354807",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "740f1691-b726-43ef-832e-9743930a06ff",
   "metadata": {},
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84d29a35-308c-4d72-9da5-f925d8a05725",
   "metadata": {},
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec1adeaf-d45d-4165-993e-4d01a1823218",
   "metadata": {},
   "source": [
    "import torch"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c419c59a-27ac-4871-b1c2-03b517500adf",
   "metadata": {},
   "source": [
    "from torcheval.metrics.functional import multiclass_accuracy"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80200fb2-6076-4168-adc3-bf7d018a5cf1",
   "metadata": {},
   "source": [
    "from sklearn.datasets import load_iris"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5e29568-8be8-4573-aeaa-05b9632dd0ea",
   "metadata": {},
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd946e53-e144-443d-b4f4-728b13a89da3",
   "metadata": {},
   "source": [
    "torch.cuda.is_available()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "40028dbc-a50d-4f57-8786-66c09608160b",
   "metadata": {},
   "source": [
    "# Intro to Deep Learning\n",
    "\n",
    "## Live Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58e2b32e-dd45-4b12-95dd-ea21545b8a8b",
   "metadata": {},
   "source": [
    "# python basic operation\n",
    "a = 10\n",
    "b = 15\n",
    "# result is of type int\n",
    "(3 * a + 4 * b) ** 2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ef6f2d4-eb0e-4fed-b484-dd17905f37cb",
   "metadata": {},
   "source": [
    "# python list manipulation similar to numpy\n",
    "a = [10, 17, 28, 13, 12]\n",
    "b = [22, 12, 55, 11, 7]\n",
    "# result is type list\n",
    "[(3 * x + 4 * y) for x, y in zip(a, b)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a73622d9-7bcc-4166-ba66-6bd7fce01122",
   "metadata": {},
   "source": [
    "# numpy version with vectorization\n",
    "a = np.array([10, 17, 28, 13, 12])\n",
    "b = np.array([22, 12, 55, 11, 7])\n",
    "print((3 * a + 4 * b) ** 2)\n",
    "print(type((3 * a + 4 * b) ** 2))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18801f66-e8cd-45a0-adce-3be6412ce0ae",
   "metadata": {},
   "source": [
    "# tensorflow version\n",
    "a = tf.constant([10, 17, 28, 13, 12])\n",
    "b = tf.constant([22, 12, 55, 11, 7])\n",
    "print((3 * a + 4 * b) ** 2)\n",
    "print(type((3 * a + 4 * b) ** 2))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9ad9561-9719-4a68-b0ac-fcf8597b6780",
   "metadata": {},
   "source": [
    "# torch version\n",
    "a = torch.tensor([10, 17, 28, 13, 12])\n",
    "b = torch.tensor([22, 12, 55, 11, 7])\n",
    "print((3 * a + 4 * b) ** 2)\n",
    "print(type((3 * a + 4 * b) ** 2))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b1162d5-285e-4911-9cc3-fc8c51fac6ee",
   "metadata": {},
   "source": [
    "# if we want to pass a clean python function to tensorflow, we decorate it (tensorflow 2.)\n",
    "def tf_input_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # Convert all positional arguments to tensors\n",
    "        tf_args = [tf.convert_to_tensor(arg) for arg in args]\n",
    "        # Convert all keyword arguments to tensors\n",
    "        tf_kwargs = {key: tf.convert_to_tensor(value) for key, value in kwargs.items()}\n",
    "        # Call the original function with TensorFlow objects\n",
    "        return func(*tf_args, **tf_kwargs)\n",
    "    return wrapper"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94dc4b85-387c-421f-952f-24873da01bfc",
   "metadata": {},
   "source": [
    "@tf_input_decorator\n",
    "def my_func(a, b):\n",
    "    return (3 * a + 4 * b) ** 2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f58cf74-b35f-4057-90ff-027b58704b5c",
   "metadata": {},
   "source": [
    "a = [10, 17, 28, 13, 12]\n",
    "b = [22, 12, 55, 11, 7]\n",
    "my_func(a, b)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fa91188-fdad-49e9-9e90-0115dea6d3fb",
   "metadata": {},
   "source": [
    "iris_df = load_iris()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8c7d8e0-3d5f-4c94-a49b-20ab9bc36d14",
   "metadata": {},
   "source": [
    "attrs, labels = iris_df.data, iris_df.target"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39b24791-8abb-4346-afa3-7faed4b1ba92",
   "metadata": {},
   "source": [
    "(attrs.shape[1], )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40bd168a-676f-4a2c-af78-155d7333489a",
   "metadata": {},
   "source": [
    "len(set(labels))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "125a7d59-dde9-4e69-9dd6-e6901616eb3e",
   "metadata": {},
   "source": [
    "model_tf = Sequential([\n",
    "    Input((attrs.shape[1],)), # input layer, shape passed count of the attributes passed as tuple\n",
    "    # no hidden layers\n",
    "    Dense(len(set(labels))) # output layer\n",
    "])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3da22b29-6a6e-46a8-b87d-a6bc00499007",
   "metadata": {},
   "source": [
    "We expect 3 logistic regressions with 4 input params each and a bias, total 15 elements for inpout and 3 for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1586f0d1-0095-4eef-94fb-cdfca309a80f",
   "metadata": {},
   "source": [
    "model_tf.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c3fca013-0f24-462b-9ae4-5744dd094cb9",
   "metadata": {},
   "source": [
    "Must define proper loss function in order to set the model as regressor or classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb762d5-a810-4509-850c-bbf6ff758fb6",
   "metadata": {},
   "source": [
    "Crossentropy is the classification loss function. Binary (for 2 classes) and categorigal (for > 2 classes). If the data is 'normal', this means that all the classes are listed in one column, before one-hot-encoding, must use 'sparse CE', if the data is like OHE, then use 'categorical CE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07556cd2-370b-4446-9979-f36af4164fe6",
   "metadata": {},
   "source": [
    "model_tf.compile(loss='sparse_categorical_crossentropy')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0090754f-666f-4725-b67f-73a296c27d11",
   "metadata": {},
   "source": [
    "The model expects probas, this means that it has to sum to 1. We need activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ca0faa3-42ad-449e-b56c-0a5d41beb506",
   "metadata": {},
   "source": [
    "model_tf = Sequential([\n",
    "    Input((attrs.shape[1],)), # input layer, shape passed count of the attributes passed as tuple\n",
    "    # no hidden layers\n",
    "    Dense(len(set(labels)), activation='softmax') # output layer\n",
    "])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a226338a-aaf7-4ccc-aff9-1c24ca38f209",
   "metadata": {},
   "source": [
    "If activation is not stated, the model will collapse to basic linear regression. **softmax** is used with more than 1 class. If only one class - **sigmoid**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7c0c0eb-f7ff-4246-845c-8b16547e7def",
   "metadata": {},
   "source": [
    "model_tf.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a535878a-df94-49b1-bfb0-9fe9fd590cf7",
   "metadata": {},
   "source": [
    "**optimizer** or solver is the algorithm used for gradient descent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18cef06a-1994-470d-8976-9c6a7bf2cc24",
   "metadata": {},
   "source": [
    "model_tf.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5520ec94-7245-437b-997b-23f2dd6e7bb2",
   "metadata": {},
   "source": [
    "Then we fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bd84dbe-3fa2-4204-ae40-168a16ae3d74",
   "metadata": {},
   "source": [
    "model_tf.fit(attrs, labels)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cc7bc200-359b-4eb8-a07b-e4d63b1ff0f2",
   "metadata": {},
   "source": [
    "Output Breakdown\n",
    "1. 5/5\n",
    "\n",
    "Indicates the number of batches processed out of the total number of batches in the epoch.\n",
    "Here, 5 is both the current batch count and the total batch count, meaning the training data was split into 5 batches for this epoch.\n",
    "\n",
    "2. [==============================]\n",
    "\n",
    "A visual representation of the progress of the current epoch. The bar fills up as training progresses through the batches.\n",
    "\n",
    "3. - 2s\n",
    "\n",
    "The time taken to complete the current epoch (in this case, 2 seconds).\n",
    "\n",
    "4. 5ms/step\n",
    "\n",
    "The average time (in milliseconds) taken to process one batch (or step) during training.\n",
    "\n",
    "5. loss: 4.1142\n",
    "\n",
    "The loss value calculated at the end of the epoch.\n",
    "This value is the output of the loss function used during training and reflects how well the model is performing on the training data. A lower value generally indicates better performance.\n",
    "\n",
    "6. <keras.callbacks.History at 0x7f4a70470250>\n",
    "\n",
    "After training, Keras returns a History object, which contains the details of the training process, such as loss values and metrics for each epoch.\n",
    "The memory address (0x7f4a70470250) indicates where this History object is stored in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "824bc9ba-dea0-446d-9a63-fbefcc22ac87",
   "metadata": {},
   "source": [
    "history = model_tf.fit(attrs, labels)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c7cfad26-a054-41c1-aabf-5bd317598ad7",
   "metadata": {},
   "source": [
    "The fit is partial fit, so every time we run a 'fit' it is not reseting but instead fitting the data to the model once again. The loss function is being reduced. If we increase the **batch** per epoch, the result is more processed batched per epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76ee4a1d-a57b-4fcb-bc8f-dac464876d36",
   "metadata": {},
   "source": [
    "model_tf.fit(attrs, labels, batch_size=8)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3790cd53-55f9-4e36-9022-0cf34281576c",
   "metadata": {},
   "source": [
    "This is the 3rd training of the model on the data. Each training is called **epoch**. We set the epoch so it is done automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82aca863-bb1f-4f22-810b-ff091fa9381b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model_tf.fit(attrs, labels, batch_size=8, epochs=1000)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3e208d76-2375-4a42-a1b7-3b1666129eb4",
   "metadata": {},
   "source": [
    "In order to initialize the model again, we need to clear the session. If we run the basic cell, the model number is increased and previous model stored in memory. It is not good because the memory space is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "182c2b1c-4706-487d-81aa-13a3185e2478",
   "metadata": {},
   "source": [
    "model_tf = Sequential([\n",
    "    Input((attrs.shape[1],)), # input layer, shape passed count of the attributes passed as tuple\n",
    "    # no hidden layers\n",
    "    Dense(len(set(labels)), activation='softmax') # output layer\n",
    "])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7aa420e9-a415-467c-9905-1bb4fca3a94e",
   "metadata": {},
   "source": [
    "model_tf.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02e6b3bc-5600-42e1-adcb-f4f42f801864",
   "metadata": {},
   "source": [
    "# clearing the session\n",
    "tf.keras.backend.clear_session()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2b70a59-95bf-42b5-805c-b7cd58703f3e",
   "metadata": {},
   "source": [
    "model_tf = Sequential([\n",
    "    Input((attrs.shape[1],)), # input layer, shape passed count of the attributes passed as tuple\n",
    "    # no hidden layers\n",
    "    Dense(len(set(labels)), activation='softmax') # output layer and activation function\n",
    "])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "415f6953-8a19-412f-ade0-30d76d7da688",
   "metadata": {},
   "source": [
    "model_tf.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7df262c2-eef7-4d00-86a3-21e49df67546",
   "metadata": {},
   "source": [
    "model_tf.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be0014c2-8b2d-43b6-8fc2-a1608ba00b1c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "history = model_tf.fit(attrs, labels, batch_size=8, epochs=200)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ee6d0f7-be5d-49d7-8cc2-2cd68c17b04e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2fb0616-6dba-4bfe-b6b0-7ae0fec1059e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "tf.argmax(model_tf.predict(attrs), axis=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da17ed03-c3c9-41f7-aeb0-ce4356db4a33",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "labels"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "877bb848-60a8-4c74-ae5e-235f469bc3fd",
   "metadata": {},
   "source": [
    "We can add metrics while compiling the model. The metrics will be displayed and added to the **history**. It is providing the score of the model against the training set during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b005952f-1724-4c53-8edf-210cf5adf33f",
   "metadata": {},
   "source": [
    "model_tf.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f494af9d-8b61-4860-a3d5-804811c92004",
   "metadata": {},
   "source": [
    "model_tf.fit(attrs, labels, batch_size=8)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eaf9c91f-6d15-4103-901c-de656fb13375",
   "metadata": {},
   "source": [
    "model_tf.evaluate(attrs, labels) # score in scikit learn"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4b3892e2-59cd-445a-b17a-0e62b6a7e713",
   "metadata": {},
   "source": [
    "Going deep in TensorFlow by adding **Dense** layer with **relu** activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5804f56b-2016-4c4e-bd1c-dcdd87a8d759",
   "metadata": {},
   "source": [
    "model_tf = Sequential([\n",
    "    Input((attrs.shape[1],)), # input layer, shape passed count of the attributes passed as tuple\n",
    "    Dense(20, activation='relu'), # hidden layer\n",
    "    Dense(10, activation='relu'), # hidden layer\n",
    "    Dense(len(set(labels)), activation='softmax') # output layer and activation function\n",
    "])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "39cdb76e-9ca8-481f-8742-1ca98c6c13e3",
   "metadata": {},
   "source": [
    "model_tf.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5f0c3262-b3d6-49ae-9769-217636d5d2b6",
   "metadata": {},
   "source": [
    "model_tf.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d328ec0e-50ab-41d2-85db-715e30980669",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model_tf.fit(attrs, labels, batch_size=8, epochs=100)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "32d28b04-eb83-4b3d-8af4-a78bf0d2b925",
   "metadata": {},
   "source": [
    "A model constructed this way would require less *epochs* to reach minimum loss. Therefore, the deeper model has bigger capacity and is training a lot faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a43ad9e-6875-41e1-b499-951706c5e16c",
   "metadata": {},
   "source": [
    "### Pytorch\n",
    "\n",
    "Pytorch has an OOP based API. Must convert all the values to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8cffc9d6-1ca1-4c7a-bbe2-001092237a0b",
   "metadata": {},
   "source": [
    "class LogisticRegressionPT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegressionPT, self).__init__()\n",
    "        self.layer = torch.nn.Linear(n_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.softmax(self.layer(x), dim=1)\n",
    "        return x"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6bcf3364-fa38-4aa4-aee7-d3ce0cdc9d9e",
   "metadata": {},
   "source": [
    "n_features = attrs.shape[1]\n",
    "n_classes = len(set(labels))\n",
    "pt_model = LogisticRegressionPT()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c5fc8ef-f12e-4d86-8f1d-3174fae35f37",
   "metadata": {},
   "source": [
    "print(pt_model)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c4bff23-eac2-4399-86d3-a81c8e085810",
   "metadata": {},
   "source": [
    "# conveert the data to pytorch tensors\n",
    "attrs_pt = torch.FloatTensor(attrs)\n",
    "labels_pt = torch.LongTensor(labels)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d6c3461f-8a03-4157-bff0-ecf8ed6d9c0e",
   "metadata": {},
   "source": [
    "learning_rate = 0.01\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(pt_model.parameters(), lr=learning_rate)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "143bbe07-57ea-435a-a6e5-8f896e49a226",
   "metadata": {},
   "source": [
    "# training the model by creating a function\n",
    "def train(model, optimizer, criterion, X, y, num_epochs, train_losses):\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output_train = model(X) # forward\n",
    "\n",
    "        loss_train = criterion(output_train, y)\n",
    "        loss_train.backward() # backward\n",
    "        optimizer.step() # weights update\n",
    "\n",
    "        train_losses[epoch] = loss_train.item()\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f'Epoch: {epoch + 1} / {num_epochs}, Loss: {loss_train.item():.4f}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3900c1b5-7bd3-4b1b-b520-70a7813b35d1",
   "metadata": {},
   "source": [
    "num_epochs = 200\n",
    "train_losses = np.zeros(num_epochs)\n",
    "\n",
    "train(pt_model, optimizer, criterion, attrs_pt, labels_pt, num_epochs, train_losses)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "957f3856-b667-4f3a-ba20-37ef71c4e619",
   "metadata": {},
   "source": [
    "Fast fitting can be achieved using **PyTorch lightning**. This is analogue to **keras**. It is additional package that must be installed. In addition, saves writing of code.\n",
    "\n",
    "The evaluation is done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7e57150f-cd70-4ee1-bc5c-d9b7572f17a5",
   "metadata": {},
   "source": [
    "predictions = torch.argmax(pt_model.forward(attrs_pt), dim=1)\n",
    "multiclass_accuracy(predictions, labels_pt)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2534c19b-8e11-4927-b99d-9a007ec0c056",
   "metadata": {},
   "source": [
    "Adding layer of neurons is done in tha class. However, the output of the first layer is the input of the second layer and so on. The final layer has the final output. The function of the final layer is kept **softmax**. The rest are changed to **relu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09abb287-b60a-470d-a5b8-55c0c5e94a5d",
   "metadata": {},
   "source": [
    "class LogisticRegressionPT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegressionPT, self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(n_features, 20)\n",
    "        self.layer2 = torch.nn.Linear(20, 10)\n",
    "        self.layer3 = torch.nn.Linear(10, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.layer1(x), dim=1)\n",
    "        x = torch.nn.functional.relu(self.layer2(x), dim=1)\n",
    "        x = torch.nn.functional.softmax(self.layer3(x), dim=1)\n",
    "        return x"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9c571f3b-5ecf-4ed0-a48b-287762bf2cab",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
